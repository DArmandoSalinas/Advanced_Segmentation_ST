"""
APREU Segmentaci√≥n Avanzada - POC Interactivo
Una aplicaci√≥n Streamlit integral que muestra tres estrategias de segmentaci√≥n distintas.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import os
from datetime import datetime

# Page configuration
st.set_page_config(
    page_title="SEGMENTACI√ìN AVANZADA DE APREU",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Memory optimization
import gc
import os
os.environ['PYARROW_IGNORE_TIMEZONE'] = '1'

# Custom CSS for better UI
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #555;
        text-align: center;
        padding-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
    .stTabs [data-baseweb="tab"] {
        height: 3rem;
        font-size: 1.1rem;
    }
</style>
""", unsafe_allow_html=True)

# Import cluster-specific modules
from cluster1_analysis import render_cluster1
from cluster2_analysis import render_cluster2
from cluster3_analysis import render_cluster3
from utils import load_data, display_metrics, create_segment_pie_chart, validate_data, apply_global_filters
from geo_config import render_geo_config_ui, get_geo_config

def main():
    """Main application entry point"""
    
    # Header
    st.markdown('<h1 class="main-header">üéØ APREU SEGMENTACI√ìN AVANZADA</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Prueba de Concepto - An√°lisis Interactivo por Segmentaci√≥n</p>', unsafe_allow_html=True)
    
    # Sidebar navigation
    with st.sidebar:
        # Display logo
        from pathlib import Path
        from PIL import Image
        
        logo_path = Path("app/assets/corchetes-blanco.webp")
        if logo_path.exists():
            try:
                logo_img = Image.open(logo_path)
                st.image(logo_img, use_container_width=True)
            except Exception as e:
                st.error(f"Error loading logo: {e}")
                st.markdown("### üéØ APREU")
        else:
            st.markdown("### üéØ APREU")
        st.markdown("---")
        
        st.markdown("### üìÅ Fuente de Datos")
        
        # File upload option
        data_source = st.radio(
            "Elegir fuente de datos:",
            ["üìÇ Usar Archivo Predeterminado", "‚¨ÜÔ∏è Subir CSV", "‚òÅÔ∏è Cargar desde Cloud Storage"],
            index=0
        )
        
        uploaded_file = None
        
        # Initialize session state for data persistence
        if 'loaded_data' not in st.session_state:
            st.session_state.loaded_data = None
        if 'data_source_info' not in st.session_state:
            st.session_state.data_source_info = None
        
        # Use cached data if available
        data = st.session_state.loaded_data
        gcs_bucket = None
        gcs_path = None
        
        if data_source == "‚òÅÔ∏è Cargar desde Cloud Storage":
            st.markdown("**Cargar desde Google Cloud Storage:**")
            st.info("üí° **Para archivos grandes (>32MB):** Usa el bucket compartido del proyecto. Solo necesitas especificar la ruta de tu archivo.")
            
            # Get default bucket from environment or use project default
            PROJECT_BUCKET = os.getenv("GCS_BUCKET_NAME", "data_clusters")
            
            # Show current loaded data info if available
            if st.session_state.loaded_data is not None and st.session_state.data_source_info:
                source_info = st.session_state.data_source_info.get('source', 'Datos cargados')
                st.success(f"‚úÖ **Datos ya cargados:** {source_info} ({len(st.session_state.loaded_data):,} contactos)")
                if st.button("üîÑ Recargar desde Cloud Storage"):
                    st.session_state.loaded_data = None
                    st.session_state.data_source_info = None
                    st.rerun()
                st.markdown("---")
            
            st.markdown(f"**üì¶ Bucket del proyecto:** `{PROJECT_BUCKET}` (pre-configurado)")
            st.caption("üí° Todos los archivos se guardan en este bucket compartido del proyecto")
            
            gcs_bucket = PROJECT_BUCKET  # Use project bucket automatically
            
            gcs_path = st.text_input(
                "üìÅ Ruta del archivo en el bucket",
                value=st.session_state.data_source_info.get('path', '') if st.session_state.data_source_info else "",
                help="Ejemplo: contacts_campus_Qro_.csv o uploads/20241112_095136_archivo.csv. La ruta es el nombre que aparece en la columna 'Name' de Cloud Storage."
            )
            
            if st.button("üîÑ Cargar desde Cloud Storage", type="primary"):
                if not gcs_path:
                    st.error("‚ùå Por favor ingresa la ruta del archivo en el bucket")
                else:
                    try:
                        with st.spinner("üì• Cargando archivo desde Cloud Storage..."):
                            data = load_data(gcs_bucket=gcs_bucket, gcs_path=gcs_path)
                            validation = validate_data(data)
                            
                            if validation['is_valid']:
                                # Save to session state for persistence
                                st.session_state.loaded_data = data
                                st.session_state.data_source_info = {
                                    'type': 'gcs',
                                    'bucket': gcs_bucket,
                                    'path': gcs_path,
                                    'source': f"gs://{gcs_bucket}/{gcs_path}"
                                }
                                
                                st.success(f"‚úÖ Cargados {len(data):,} contactos desde Cloud Storage")
                                st.info("üí° Los datos est√°n guardados y disponibles para todos los clusters. Puedes navegar entre clusters sin recargar.")
                                
                                # Show data preview
                                with st.expander("üìã Vista Previa de Datos"):
                                    st.write(f"**Fuente:** gs://{gcs_bucket}/{gcs_path}")
                                    st.write(f"**Columnas:** {len(data.columns)}")
                                    st.write(f"**Filas:** {len(data):,}")
                                    st.dataframe(data.head(3), use_container_width=True)
                                
                                # Show warnings if any
                                if validation['warnings']:
                                    with st.expander("‚ö†Ô∏è Advertencias", expanded=False):
                                        for warning in validation['warnings']:
                                            st.warning(warning)
                                
                                # Update data variable
                                data = st.session_state.loaded_data
                            else:
                                st.error(f"‚ùå Datos inv√°lidos: Faltan columnas requeridas: {', '.join(validation['missing_basic'])}")
                                data = None
                                st.session_state.loaded_data = None
                                st.session_state.data_source_info = None
                    except Exception as e:
                        st.error(f"‚ùå Error cargando desde Cloud Storage: {e}")
                        st.info("""
                        **Verifica:**
                        1. El nombre del bucket es correcto
                        2. La ruta del archivo es correcta
                        3. El servicio tiene permisos para leer el bucket
                        4. El archivo existe en Cloud Storage
                        """)
                        data = None
                        st.session_state.loaded_data = None
                        st.session_state.data_source_info = None
            
            with st.expander("üìñ ¬øC√≥mo identificar la ruta del archivo?"):
                st.markdown("""
                **La ruta es el nombre que aparece en la columna "Name" de Cloud Storage:**
                
                - **Si el archivo est√° en la ra√≠z del bucket:**
                  - Solo el nombre: `contacts_campus_Qro_.csv`
                
                - **Si el archivo est√° en una carpeta:**
                  - Incluye la carpeta: `datos/contacts_campus_Qro_.csv`
                  - O con subcarpetas: `uploads/2024/noviembre/archivo.csv`
                
                **Ejemplo pr√°ctico:**
                - Bucket: `data_clusters`
                - Nombre en la lista: `contacts_campus_Qro_.csv`
                - **Ruta a usar:** `contacts_campus_Qro_.csv` ‚úÖ
                """)
            
            with st.expander("üì§ ¬øC√≥mo subir un archivo al bucket del proyecto?"):
                st.markdown("""
                Tienes **3 formas** de subir archivos al bucket `data_clusters`:
                
                **üåê Opci√≥n 1: Desde la Consola de GCP (M√°s f√°cil)**
                1. Ve a [Cloud Storage](https://console.cloud.google.com/storage/browser/data_clusters)
                2. Haz clic en el bot√≥n **"Upload"** (arriba)
                3. Selecciona tu archivo CSV desde tu computadora
                4. Espera a que termine la subida
                5. **Anota el nombre** que aparece en la lista (esa es la ruta)
                6. Usa esa ruta en la aplicaci√≥n
                
                **üíª Opci√≥n 2: Desde la l√≠nea de comandos**
                ```bash
                # Subir archivo a la ra√≠z del bucket
                gsutil cp archivo.csv gs://data_clusters/
                # Ruta: archivo.csv
                
                # Subir archivo a una carpeta
                gsutil cp archivo.csv gs://data_clusters/datos/
                # Ruta: datos/archivo.csv
                ```
                
                **üì§ Opci√≥n 3: Desde esta aplicaci√≥n (Autom√°tico)**
                - Selecciona **"‚¨ÜÔ∏è Subir CSV"** arriba
                - Si el archivo es grande, se sube autom√°ticamente al bucket
                - No necesitas hacer nada m√°s
                
                **üí° Recomendaci√≥n:** Para archivos grandes, usa la Opci√≥n 3 (desde la app) - es la m√°s f√°cil y autom√°tica.
                """)
        
        elif data_source == "‚¨ÜÔ∏è Subir CSV":
            st.markdown("**Subir Exportaci√≥n de Contactos de HubSpot:**")
            
            # Get default bucket name from environment or use project default
            PROJECT_BUCKET = os.getenv("GCS_BUCKET_NAME", "data_clusters")
            
            uploaded_file = st.file_uploader(
                "Elegir un archivo CSV",
                type=['csv'],
                help="Sube tu archivo CSV. Archivos grandes se subir√°n autom√°ticamente a Cloud Storage."
            )
            
            if uploaded_file is not None:
                # Check file size (in bytes)
                file_size_mb = uploaded_file.size / (1024 * 1024)
                
                # If file is large, offer to upload to Cloud Storage
                if file_size_mb > 25:  # Close to the 32MB limit
                    st.warning(f"‚ö†Ô∏è **Archivo grande detectado ({file_size_mb:.1f}MB)**")
                    st.info("üí° Este archivo es grande. Te recomendamos subirlo a Cloud Storage para evitar problemas.")
                    
                    use_gcs = st.checkbox(
                        "‚òÅÔ∏è Subir a Cloud Storage autom√°ticamente",
                        value=True,
                        help="El archivo se subir√° a Cloud Storage y luego se cargar√° desde ah√≠"
                    )
                    
                    if use_gcs:
                        st.markdown(f"**üì¶ Bucket del proyecto:** `{PROJECT_BUCKET}` (pre-configurado)")
                        st.caption("üí° Tu archivo se guardar√° autom√°ticamente en el bucket compartido del proyecto")
                        
                        gcs_bucket_upload = PROJECT_BUCKET  # Use project bucket automatically
                        
                        # Generate a unique filename in uploads folder
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        default_gcs_path = f"uploads/{timestamp}_{uploaded_file.name}"
                        gcs_path_upload = st.text_input(
                            "üìÅ Ruta donde guardar (opcional)",
                            value=default_gcs_path,
                            help=f"Se guardar√° en: gs://{PROJECT_BUCKET}/uploads/ con nombre √∫nico. Puedes cambiarlo si quieres."
                        )
                        
                        if st.button("‚òÅÔ∏è Subir y Cargar desde Cloud Storage", type="primary"):
                            try:
                                with st.spinner("üì§ Subiendo archivo a Cloud Storage..."):
                                    # Upload to Cloud Storage
                                    from utils import upload_to_gcs
                                    upload_to_gcs(uploaded_file, gcs_bucket_upload, gcs_path_upload)
                                    st.success(f"‚úÖ Archivo subido a gs://{gcs_bucket_upload}/{gcs_path_upload}")
                                
                                with st.spinner("üì• Cargando datos desde Cloud Storage..."):
                                    # Load from Cloud Storage
                                    data = load_data(gcs_bucket=gcs_bucket_upload, gcs_path=gcs_path_upload)
                                    validation = validate_data(data)
                                    
                                    if validation['is_valid']:
                                        # Save to session state
                                        st.session_state.loaded_data = data
                                        st.session_state.data_source_info = {
                                            'type': 'gcs_upload',
                                            'bucket': gcs_bucket_upload,
                                            'path': gcs_path_upload,
                                            'source': f"gs://{gcs_bucket_upload}/{gcs_path_upload}"
                                        }
                                        
                                        st.success(f"‚úÖ Cargados {len(data):,} contactos")
                                        st.info("üí° Los datos est√°n guardados y disponibles para todos los clusters.")
                                        
                                        # Show data preview
                                        with st.expander("üìã Vista Previa de Datos"):
                                            st.write(f"**Fuente:** gs://{gcs_bucket_upload}/{gcs_path_upload}")
                                            st.write(f"**Columnas:** {len(data.columns)}")
                                            st.write(f"**Filas:** {len(data):,}")
                                            st.dataframe(data.head(3), use_container_width=True)
                                        
                                        # Show warnings if any
                                        if validation['warnings']:
                                            with st.expander("‚ö†Ô∏è Advertencias", expanded=False):
                                                for warning in validation['warnings']:
                                                    st.warning(warning)
                                        
                                        # Update data variable
                                        data = st.session_state.loaded_data
                                    else:
                                        st.error(f"‚ùå Datos inv√°lidos: Faltan columnas requeridas: {', '.join(validation['missing_basic'])}")
                                        data = None
                                        st.session_state.loaded_data = None
                                        st.session_state.data_source_info = None
                            except Exception as e:
                                st.error(f"‚ùå Error: {e}")
                                st.info("""
                                **Verifica:**
                                1. El bucket existe y tiene permisos correctos
                                2. El servicio tiene permisos para escribir en el bucket
                                3. Ejecuta: `./configurar_cloud_storage.sh` para configurar permisos
                                """)
                                data = None
                        else:
                            data = None
                    else:
                        # Try to load directly (may fail if too large)
                        try:
                            data = load_data(uploaded_file)
                            validation = validate_data(data)
                            
                            if validation['is_valid']:
                                # Save to session state
                                st.session_state.loaded_data = data
                                st.session_state.data_source_info = {
                                    'type': 'upload',
                                    'source': uploaded_file.name
                                }
                                st.info("üí° Los datos est√°n guardados y disponibles para todos los clusters.")
                                # Update data variable
                                data = st.session_state.loaded_data
                        except Exception as e:
                            error_msg = str(e)
                            if "413" in error_msg or "Payload Too Large" in error_msg:
                                st.error("‚ùå **Error: Archivo demasiado grande para subir directamente**")
                                st.info("üí° Por favor activa la opci√≥n 'Subir a Cloud Storage autom√°ticamente' arriba.")
                                data = None
                                st.session_state.loaded_data = None
                                st.session_state.data_source_info = None
                            else:
                                raise
                else:
                    # Small file, try to load directly
                    try:
                        data = load_data(uploaded_file)
                        validation = validate_data(data)
                        
                        if validation['is_valid']:
                            # Save to session state
                            st.session_state.loaded_data = data
                            st.session_state.data_source_info = {
                                'type': 'upload',
                                'source': uploaded_file.name
                            }
                            st.info("üí° Los datos est√°n guardados y disponibles para todos los clusters.")
                            # Update data variable
                            data = st.session_state.loaded_data
                    except Exception as e:
                        error_msg = str(e)
                        if "413" in error_msg or "Payload Too Large" in error_msg:
                            st.error("‚ùå **Error: Archivo demasiado grande**")
                            st.info("üí° Intenta usar la opci√≥n '‚òÅÔ∏è Cargar desde Cloud Storage' para archivos grandes.")
                            data = None
                            st.session_state.loaded_data = None
                            st.session_state.data_source_info = None
                        else:
                            raise
                
            else:
                st.info("üëÜ Por favor sube un archivo CSV para comenzar el an√°lisis")
        else:
            # Use default file
            try:
                # Check if we already have data loaded
                if st.session_state.loaded_data is not None:
                    data = st.session_state.loaded_data
                    if st.session_state.data_source_info:
                        st.success(f"‚úÖ Datos ya cargados: {st.session_state.data_source_info.get('source', 'Archivo predeterminado')}")
                    else:
                        st.success(f"‚úÖ Usando datos cargados previamente ({len(data):,} contactos)")
                else:
                    data = load_data()
                    # Save to session state
                    st.session_state.loaded_data = data
                    st.session_state.data_source_info = {
                        'type': 'default',
                        'source': 'data/raw/contacts_campus_Qro_.csv'
                    }
                    st.success(f"‚úÖ Cargados {len(data):,} contactos")
                    st.info("üí° Los datos est√°n guardados y disponibles para todos los clusters.")
                
                    with st.expander("‚ÑπÔ∏è Informaci√≥n de Datos"):
                        if st.session_state.data_source_info:
                            st.write(f"**Fuente:** {st.session_state.data_source_info.get('source', 'Archivo predeterminado')}")
                        else:
                            st.write("**Archivo:** data/raw/contacts_campus_Qro_.csv")
                        st.write(f"**Columnas:** {len(data.columns)}")
                        st.write(f"**Filas:** {len(data):,}")
            except Exception as e:
                st.error(f"‚ùå Error cargando archivo predeterminado: {e}")
                st.info("üí° Intenta subir tu propio archivo CSV")
                data = None
                st.session_state.loaded_data = None
                st.session_state.data_source_info = None
        
        st.markdown("---")
        
        # Global Filters Section
        st.markdown("### üéõÔ∏è Filtros Globales")
        
        with st.expander("üìÖ Filtro de Per√≠odo Acad√©mico", expanded=False):
            if data is not None:
                # Look for periodo de ingreso field
                periodo_fields = [
                    'Periodo de ingreso a licenciatura (MQL)', 
                    'Periodo de ingreso',
                    'periodo_de_ingreso',
                    'PERIODO DE INGRESO'
                ]
                
                periodo_col = None
                for field in periodo_fields:
                    if field in data.columns:
                        periodo_col = field
                        break
                
                if periodo_col:
                    # Convert periodo codes to readable format
                    # Based on YYYYMM format where MM codes are:
                    # 05 = Special, 10 = Spring, 35 = Summer, 60 = Fall, 75 = Winter/Special
                    def convert_periodo(val):
                        try:
                            if pd.isna(val):
                                return "Unknown"
                            periodo_str = str(int(float(val))).strip()
                            if len(periodo_str) != 6:
                                return "Unknown"
                            year = periodo_str[:4]
                            period_code = int(periodo_str[4:])
                            
                            # Map period codes to semester names (from notebooks)
                            period_map = {
                                5: "Especial",
                                10: "Primavera", 
                                35: "Verano",
                                60: "Oto√±o",
                                75: "Invierno/Especial"
                            }
                            
                            semester = period_map.get(period_code, f"Desconocido({period_code})")
                            return f"{year} {semester}"
                        except:
                            return "Desconocido"
                    
                    import pandas as pd
                    from utils import hist_latest
                    
                    # Get latest periodo values
                    periodo_latest = data[periodo_col].apply(hist_latest)
                    periodo_readable = periodo_latest.apply(convert_periodo)
                    available_periodos = sorted([p for p in periodo_readable.unique() if p != "Desconocido"])
                    
                    if available_periodos:
                        selected_periodos = st.multiselect(
                            "Seleccionar Per√≠odo(s) de Ingreso:",
                            options=available_periodos,
                            default=[],
                            help="Filtrar contactos por su per√≠odo de ingreso (dejar vac√≠o para todos)"
                        )
                        
                        st.session_state['filter_periodos'] = selected_periodos
                    else:
                        st.info("No se encontraron datos v√°lidos de per√≠odo de ingreso")
                else:
                    st.info("üìÖ Campo de per√≠odo de ingreso no encontrado en el dataset")
            else:
                st.info("Cargar datos para ver filtro de per√≠odo")
        
        with st.expander("üíº Filtro de Estado de Cierre", expanded=False):
            closure_status = st.radio(
                "Estado de Cierre:",
                ["Todos los Contactos", "Solo Cerrados", "Solo Abiertos"],
                index=0,
                help="Filtrar por estado de cierre de tratos"
            )
            
            # Store in session state
            st.session_state['filter_closure_status'] = closure_status
        
        with st.expander("üîÑ Filtros de Ciclo de Vida", expanded=False):
            if data is not None:
                from utils import hist_latest
                import pandas as pd
                
                lifecycle_col = 'Lifecycle Stage' if 'Lifecycle Stage' in data.columns else 'lifecycle_stage'
                if lifecycle_col in data.columns:
                    # Get LATEST lifecycle stage values only
                    lifecycle_latest = data[lifecycle_col].apply(hist_latest)
                    available_stages = sorted([str(x) for x in lifecycle_latest.dropna().unique() if str(x).lower() not in ['other', 'subscriber', 'nan', 'none', '']])
                    
                    if available_stages:
                        selected_stages = st.multiselect(
                            "Seleccionar Etapas del Ciclo de Vida (dejar vac√≠o para todas):",
                            options=available_stages,
                            default=[],
                            help="Filtrar a etapas espec√≠ficas del ciclo de vida (usa solo el valor M√ÅS RECIENTE)"
                        )
                        
                        st.session_state['filter_lifecycle_stages'] = selected_stages
                    else:
                        st.info("No se encontraron etapas v√°lidas del ciclo de vida")
                else:
                    st.info("Datos de etapa del ciclo de vida no disponibles")
        
        # Reset filters button
        if st.button("üîÑ Restablecer Todos los Filtros", use_container_width=True):
            for key in list(st.session_state.keys()):
                if key.startswith('filter_'):
                    del st.session_state[key]
            st.rerun()
        
        # Show active filters count
        active_filters = sum(1 for k in st.session_state.keys() if k.startswith('filter_'))
        if active_filters > 0:
            st.info(f"‚úÖ {active_filters} filtro(s) activo(s)")
        
        st.markdown("---")
        
        # Geographic configuration (for Cluster 2)
        render_geo_config_ui()
        
        st.markdown("---")
        st.markdown("### üìä Navegaci√≥n")
        
        cluster_choice = st.radio(
            "Seleccionar Estrategia de Segmentaci√≥n:",
            ["üè† Resumen", "üì± Cluster 1: Compromiso Social", "üåç Cluster 2: Geograf√≠a y Compromiso", 
             "üé™ Cluster 3: Actividades APREU"],
            index=0,
            disabled=(data is None)
        )
        
        st.markdown("---")
        st.markdown("### üìñ Referencia R√°pida")
        
        with st.expander("üéØ ¬øQu√© Cluster Debo Usar?"):
            st.markdown("""
            **üì± Cluster 1: Estrategia de Redes Sociales**
            - *Cu√°ndo:* Optimizar campa√±as de redes sociales
            - *Para:* Asignaci√≥n de presupuesto por plataforma
            - *Responde:* ¬øQu√© plataformas convierten mejor?
            
            **üåç Cluster 2: Campa√±as Regionales**
            - *Cu√°ndo:* Planificar alcance geogr√°fico
            - *Para:* Estrategia de marketing regional
            - *Responde:* ¬øQu√© regiones tienen mejor rendimiento?
            
            **üé™ Cluster 3: Planificaci√≥n de Eventos**
            - *Cu√°ndo:* Optimizar actividades promocionales
            - *Para:* An√°lisis de ROI de eventos APREU
            - *Responde:* ¬øQu√© eventos impulsan conversiones?
            
            ---
            
            **üí° Consejo Pro:** ¬°Usa m√∫ltiples clusters juntos!
            - Cluster 1 + 2 = Estrategia social por regi√≥n
            - Cluster 2 + 3 = Planificaci√≥n de eventos por geograf√≠a
            - Los 3 = Estrategia de marketing integral
            """)
        
        st.markdown("---")
        st.markdown("### ‚ÑπÔ∏è Acerca de")
        st.info("""
        **POC de Segmentaci√≥n Avanzada**
        
        Esta aplicaci√≥n muestra tres enfoques complementarios de segmentaci√≥n:
        
        - **Cluster 1**: Actividad en redes sociales y compromiso por plataforma
        - **Cluster 2**: Distribuci√≥n geogr√°fica y niveles de compromiso  
        - **Cluster 3**: Actividades promocionales y canales de entrada
        
        **Filtros Globales Disponibles:**
        - üìÖ Per√≠odo Acad√©mico (Per√≠odo de Ingreso)
        - üîÑ Etapa del Ciclo de Vida (valor m√°s reciente)
        - üíº Estado de Cierre (Abierto/Cerrado/Todos)
        
        Cada cluster tambi√©n tiene filtros espec√≠ficos para an√°lisis m√°s profundos.
        
        **Pipeline de Datos:**
        1. Total Contactos ‚Üí 2. Contactos APREU ‚Üí 3. Remover "other"/"subscriber" ‚Üí 4. Contactos de Trabajo
        """)
        
        # Download template
        st.markdown("---")
        st.markdown("### üì• ¬øNecesitas Ayuda?")
        
        with st.expander("Formato de Datos Requerido"):
            st.markdown("""
            **Tu CSV debe incluir:**
            
            **Campos B√°sicos:**
            - Record ID (identificador de contacto)
            - Propiedad del contacto (para filtrar por APREU)
            
            **Para Filtros Globales:**
            - Per√≠odo de ingreso (per√≠odo de admisi√≥n - formato: YYYYMM, ej., 202460 = Oto√±o 2024)
            - Etapa del Ciclo de Vida (usar√° el valor m√°s reciente, remover√° "other" y "subscriber")
            - Fecha de Cierre (para filtro de estado de cierre)
            
            **Para Cluster 1 (Social):**
            - Fuente Original
            - Clics de Broadcast/LinkedIn/Twitter/Facebook
            - N√∫mero de Sesiones, P√°ginas Vistas, Env√≠os de Formularios
            
            **Para Cluster 2 (Geograf√≠a):**
            - Pa√≠s IP, Estado/Regi√≥n IP
            - Campos de ubicaci√≥n de preparatoria
            - N√∫mero de Sesiones, P√°ginas Vistas, Env√≠os de Formularios
            
            **Para Cluster 3 (APREU):**
            - Actividades de promoci√≥n APREU
            - Primera Conversi√≥n/Conversi√≥n Reciente
            - Informaci√≥n de preparatoria
            
            **Nota:** Los campos con valores hist√≥ricos (delimitador: //) usar√°n el valor m√°s reciente para filtrar.
            
            **C√≥digos de Per√≠odo:** 05=Especial, 10=Primavera, 35=Verano, 60=Oto√±o, 75=Invierno/Especial
            """)
        
        if st.button("üìÑ Ver Estructura de Datos de Ejemplo", use_container_width=True):
            if data is not None:
                st.info("Columnas de ejemplo de los datos cargados:")
                st.code('\n'.join(data.columns[:20].tolist()))
            else:
                st.info("Cargar datos primero para ver estructura de columnas")
    
    # Main content area
    if data is None:
        st.warning("‚ö†Ô∏è No hay datos cargados. Por favor elige una opci√≥n para cargar tus datos.")
        st.markdown("---")
        st.markdown("### üöÄ Comenzando - C√≥mo Cargar tus Datos")
        st.markdown("""
        Tienes **3 opciones** para cargar tus datos. Elige la que mejor se adapte a tu situaci√≥n:
        """)
        
        # Option 1
        with st.expander("üìÇ Opci√≥n 1: Usar Archivo Predeterminado", expanded=False):
            st.markdown("""
            **¬øCu√°ndo usar esta opci√≥n?**
            - Si ya tienes un archivo CSV guardado en el servidor
            - Para pruebas r√°pidas con datos de ejemplo
            
            **Pasos:**
            1. Aseg√∫rate de que el archivo `contacts_campus_Qro_.csv` est√© en el directorio `data/raw/`
            2. En la barra lateral izquierda, selecciona **"üìÇ Usar Archivo Predeterminado"**
            3. Los datos se cargar√°n autom√°ticamente
            
            **‚úÖ Ventajas:** R√°pido, no necesitas subir nada
            """)
        
        # Option 2
        with st.expander("‚¨ÜÔ∏è Opci√≥n 2: Subir CSV Directamente", expanded=False):
            st.markdown("""
            **¬øCu√°ndo usar esta opci√≥n?**
            - Si tu archivo CSV es **menor a 25MB**
            - Para archivos peque√±os o medianos
            - Cuando quieres subir datos directamente desde tu computadora
            
            **Pasos:**
            1. Exporta tus contactos de HubSpot como archivo CSV
            2. En la barra lateral, selecciona **"‚¨ÜÔ∏è Subir CSV"**
            3. Haz clic en el bot√≥n de subir y selecciona tu archivo CSV
            4. Espera a que se valide y cargue (puede tardar unos segundos)
            
            **‚úÖ Ventajas:** F√°cil y r√°pido para archivos peque√±os  
            **‚ö†Ô∏è Limitaci√≥n:** Archivos mayores a 32MB pueden fallar
            """)
        
        # Option 3 - Cloud Storage
        with st.expander("‚òÅÔ∏è Opci√≥n 3: Cargar desde Cloud Storage (Recomendado para archivos grandes)", expanded=True):
            st.markdown("""
            **¬øCu√°ndo usar esta opci√≥n?**
            - Si tu archivo CSV es **mayor a 25MB** o muy grande
            - Cuando necesitas trabajar con archivos de cualquier tama√±o
            - Para archivos que ya est√°n en Google Cloud Storage
            
            **Pasos:**
            
            **A) Si tu archivo ya est√° en Cloud Storage:**
            1. En la barra lateral, selecciona **"‚òÅÔ∏è Cargar desde Cloud Storage"**
            2. El bucket ya est√° pre-configurado (`data_clusters`) - no necesitas cambiarlo
            3. Ingresa solo la **ruta del archivo** (ej: `contacts_campus_Qro_.csv`)
               - üí° La ruta es el nombre que aparece en la columna "Name" de Cloud Storage
               - Si est√° en una carpeta: `uploads/20241112_095136_archivo.csv`
            4. Haz clic en **"üîÑ Cargar desde Cloud Storage"**
            
            **B) Si necesitas subir tu archivo primero:**
            1. Sube tu archivo CSV al bucket del proyecto:
               - Desde la [consola de GCP](https://console.cloud.google.com/storage): Ve a Cloud Storage ‚Üí Bucket `data_clusters` ‚Üí "Upload"
               - O desde la l√≠nea de comandos: `gsutil cp archivo.csv gs://data_clusters/`
            2. Luego sigue los pasos del punto A arriba (solo necesitas la ruta del archivo)
            
            **üí° Simplificado:** El bucket `data_clusters` est√° pre-configurado para todo el proyecto. Solo necesitas especificar la ruta de tu archivo.
            
            **‚úÖ Ventajas:** 
            - ‚úÖ Funciona con archivos de **cualquier tama√±o** (sin l√≠mites)
            - ‚úÖ Los datos se guardan y est√°n disponibles para todos los clusters
            - ‚úÖ No necesitas recargar al cambiar de cluster
            
            **üí° Tip:** Si subes un archivo grande directamente (Opci√≥n 2), la aplicaci√≥n te ofrecer√° subirlo autom√°ticamente a Cloud Storage.
            """)
        
        st.markdown("---")
        st.markdown("### üí° Consejos Importantes")
        st.info("""
        **üìä Una vez cargados los datos:**
        - Los datos quedan **guardados en tu sesi√≥n**
        - Puedes navegar entre todos los clusters sin recargar
        - Los datos estar√°n disponibles hasta que cierres la aplicaci√≥n o recargues
        
        **üîç ¬øNecesitas ayuda?**
        - Revisa la secci√≥n **"Formato de Datos Requerido"** en la barra lateral
        - Ve la estructura de datos de ejemplo usando el bot√≥n en la barra lateral
        - Si tienes problemas, verifica que tu archivo CSV tenga las columnas requeridas
        """)
        
        st.markdown("---")
        st.markdown("### ‚ùì ¬øCu√°l Opci√≥n Elegir?")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            **üìÇ Archivo Predeterminado**
            - ‚úÖ Ya est√° configurado
            - ‚úÖ Carga instant√°nea
            - ‚ö†Ô∏è Solo si existe el archivo
            """)
        
        with col2:
            st.markdown("""
            **‚¨ÜÔ∏è Subir CSV**
            - ‚úÖ F√°cil y directo
            - ‚úÖ Para archivos < 25MB
            - ‚ö†Ô∏è L√≠mite de tama√±o
            """)
        
        with col3:
            st.markdown("""
            **‚òÅÔ∏è Cloud Storage**
            - ‚úÖ Sin l√≠mite de tama√±o
            - ‚úÖ Archivos grandes
            - ‚úÖ M√°s estable
            """)
    else:
        # Apply global filters
        filtered_data, filters_applied = apply_global_filters(data)
        
        # Show filter status
        if len(filters_applied) > 0:
            with st.expander(f"üîç Filtros Activos ({len(filters_applied)})", expanded=False):
                st.markdown("**Filtros aplicados:**")
                for f in filters_applied:
                    st.markdown(f"- {f}")
                st.markdown(f"**Resultado:** {len(filtered_data):,} de {len(data):,} contactos ({len(filtered_data)/len(data)*100:.1f}%)")
        
        # Route to appropriate cluster with filtered data
        if cluster_choice == "üè† Resumen":
            render_overview(filtered_data)
        elif cluster_choice == "üì± Cluster 1: Compromiso Social":
            render_cluster1(filtered_data)
        elif cluster_choice == "üåç Cluster 2: Geograf√≠a y Compromiso":
            render_cluster2(filtered_data)
        elif cluster_choice == "üé™ Cluster 3: Actividades APREU":
            render_cluster3(filtered_data)

def render_overview(data):
    """Render the overview dashboard"""
    
    st.markdown("## üìä Resumen Ejecutivo")
    st.markdown("---")
    
    if data is None:
        st.error("‚ö†Ô∏è Datos no cargados. Por favor revisa el archivo de datos.")
        return
    
    # Calculate key metrics with clear pipeline
    from utils import hist_latest
    
    # 1. Total contacts
    total_contacts = len(data)
    
    # 2. APREU contacts
    propiedad_col = 'Propiedad del contacto' if 'Propiedad del contacto' in data.columns else 'propiedad_del_contacto'
    if propiedad_col in data.columns:
        data_with_propiedad = data.copy()
        data_with_propiedad[propiedad_col] = data_with_propiedad[propiedad_col].apply(hist_latest)
        apreu_contacts = data_with_propiedad[data_with_propiedad[propiedad_col] == 'APREU']
        apreu_count = len(apreu_contacts)
    else:
        apreu_contacts = data
        apreu_count = total_contacts
    
    # 3. Contacts after removing "other" and "subscriber"
    lifecycle_col = 'Lifecycle Stage' if 'Lifecycle Stage' in data.columns else 'lifecycle_stage'
    if lifecycle_col in apreu_contacts.columns:
        apreu_contacts_cleaned = apreu_contacts.copy()
        apreu_contacts_cleaned[lifecycle_col] = apreu_contacts_cleaned[lifecycle_col].apply(hist_latest)
        working_contacts = apreu_contacts_cleaned[~apreu_contacts_cleaned[lifecycle_col].str.lower().isin(['other', 'subscriber'])]
        working_count = len(working_contacts)
    else:
        working_contacts = apreu_contacts
        working_count = apreu_count
    
    # 4. Closed contacts (from working contacts)
    close_col = 'close_date' if 'close_date' in working_contacts.columns else 'Close Date'
    closed_count = working_contacts[close_col].notna().sum() if close_col in working_contacts.columns else 0
    close_rate = (closed_count / working_count * 100) if working_count > 0 else 0
    
    # Display metrics
    st.markdown("### üìä Pipeline de Contactos")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Contactos", f"{total_contacts:,}", help="Todos los contactos en el dataset")
    
    with col2:
        apreu_pct = (apreu_count / total_contacts * 100) if total_contacts > 0 else 0
        st.metric("Contactos APREU", f"{apreu_count:,}", delta=f"{apreu_pct:.1f}%", help="Contactos donde Propiedad = APREU")
    
    with col3:
        removed = apreu_count - working_count
        st.metric("Despu√©s de Limpieza", f"{working_count:,}", delta=f"-{removed:,}", delta_color="off", help="Contactos APREU despu√©s de remover etapas 'other' y 'subscriber' del ciclo de vida")
    
    with col4:
        st.metric("Tratos Cerrados", f"{closed_count:,}", delta=f"{close_rate:.1f}%", help="Contactos cerrados del conjunto de trabajo")
    
    st.markdown("---")
    
    # Cluster Comparison Section
    st.markdown("### üéØ Comparaci√≥n de Estrategias de Segmentaci√≥n")
    
    tab1, tab2, tab3 = st.tabs(["üì± Cluster 1", "üåç Cluster 2", "üé™ Cluster 3"])
    
    with tab1:
        st.markdown("""
        #### Cluster 1: Prospectos Socialmente Comprometidos
        
        **Objetivo:** Identificar y segmentar prospectos con actividad en redes sociales usando an√°lisis avanzado de datos hist√≥ricos 
        y detecci√≥n multi-plataforma.
        
        **Caracter√≠sticas Clave:**
        - ‚úÖ An√°lisis integral de datos hist√≥ricos (TODOS los valores, no solo el m√°s reciente)
        - ‚úÖ Detecci√≥n multi-plataforma (12+ plataformas: Instagram, TikTok, LinkedIn, Facebook, etc.)
        - ‚úÖ Filtrado inteligente para contactos APREU
        - ‚úÖ Etiquetado inteligente de plataformas usando datos hist√≥ricos + clics
        - ‚úÖ An√°lisis avanzado de cierre con buckets de tiempo-hasta-cierre
        - ‚úÖ Seguimiento de integraci√≥n del ciclo de vida
        - ‚úÖ Filtros interactivos (segmento, plataforma, clics sociales, puntuaci√≥n de compromiso)
        - ‚úÖ Benchmarking de rendimiento con an√°lisis de cuartiles
        - ‚úÖ Exportaciones CSV (datos completos, resumen, desglose por plataforma)
        
        **Segmentos:**
        - **1A. Alto Compromiso + Actividad Social**: Usuarios sociales activos, mayor tasa de cierre
        - **1B. Bajo Compromiso + Actividad Social**: Presencia social pero interacci√≥n m√≠nima
        
        **Superposiciones de Plataforma:** Compromiso combinado + etiquetas de plataforma (ej., "1A + Google_Ads", "1B + Facebook")
        
        **Pesta√±as Disponibles:** Resumen, An√°lisis de Segmento, An√°lisis de Plataforma, Resultados de Negocio, Cerradores R√°pidos/Lentos, Per√≠odo Acad√©mico, Benchmarks de Rendimiento, B√∫squeda de Contactos
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            st.info("**Caso de Uso Principal:** Optimizaci√≥n del equipo de redes sociales, asignaci√≥n de presupuesto por plataforma, campa√±as de remarketing")
        with col2:
            st.success("**Esperado:** Contactos comprometidos divididos en 1A/1B con etiquetas de plataforma")
    
    with tab2:
        st.markdown("""
        #### Cluster 2: Segmentaci√≥n por Geograf√≠a y Compromiso
        
        **Objetivo:** Segmentar contactos por geograf√≠a (Local/For√°neo/Internacional) y nivel de compromiso 
        en 6 subclusters accionables.
        
        **Caracter√≠sticas Clave:**
        - ‚úÖ Clasificaci√≥n geogr√°fica (Local, For√°neo, Internacional) - ¬°Configurable!
        - ‚úÖ Puntuaci√≥n de compromiso por nivel geo con umbrales de cuantil (percentil 70)
        - ‚úÖ Normalizaci√≥n mejorada de estados (32 estados mexicanos + variantes CDMX)
        - ‚úÖ An√°lisis de rendimiento a nivel estatal y clasificaci√≥n de niveles
        - ‚úÖ Configuraci√≥n geo din√°mica (cambiar pa√≠s de origen y regi√≥n local)
        - ‚úÖ An√°lisis de tiempo-hasta-cierre por geograf√≠a
        - ‚úÖ Filtros interactivos (segmento, nivel geo, pa√≠s, nivel de compromiso)
        - ‚úÖ Benchmarking de rendimiento por geograf√≠a y pa√≠s
        - ‚úÖ Exportaciones CSV (datos completos, resumen, desglose geogr√°fico)
        
        **Segmentos:**
        - **2A**: For√°neo (no local), Alto Compromiso
        - **2B**: For√°neo (no local), Bajo Compromiso  
        - **2C**: Internacional, Alto Compromiso
        - **2D**: Internacional, Bajo Compromiso
        - **2E**: Local, Alto Compromiso
        - **2F**: Local, Bajo Compromiso
        
        **Pesta√±as Disponibles:** Resumen, An√°lisis de Segmento, An√°lisis Geogr√°fico, Resultados de Negocio, Cerradores R√°pidos/Lentos, Benchmarks de Rendimiento, B√∫squeda de Contactos
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            st.info("**Caso de Uso Principal:** Campa√±as de marketing regional, reclutamiento internacional, compromiso local QRO")
        with col2:
            st.success("**Segmentos Esperados:** 6 segmentos principales (2A-2F) + sub-segmentos espec√≠ficos por estado para for√°neos")
    
    with tab3:
        st.markdown("""
        #### Cluster 3: Convertidores Impulsados por Promoci√≥n (Actividades APREU)
        
        **Objetivo:** Segmentar contactos por actividades promocionales y canales de entrada usando an√°lisis 
        integral de actividades hist√≥ricas APREU.
        
        **Caracter√≠sticas Clave:**
        - ‚úÖ An√°lisis integral de actividades hist√≥ricas APREU (TODOS los eventos asistidos)
        - ‚úÖ Detecci√≥n multi-actividad (Open Day, Fogatada, TDLA, Gira Panam√°, WhatsApp, etc.)
        - ‚úÖ Clasificaci√≥n inteligente de canales de entrada (Digital/Evento/Mensajer√≠a/Nicho)
        - ‚úÖ An√°lisis cruzado de preparatoria por actividad
        - ‚úÖ Seguimiento de eventos de conversi√≥n (primera + conversi√≥n reciente)
        - ‚úÖ Visualizaci√≥n del viaje de actividad por contacto
        - ‚úÖ An√°lisis de compromiso por email y l√≠nea de tiempo de conversi√≥n
        - ‚úÖ An√°lisis de per√≠odo acad√©mico con tendencias estacionales
        
        **Segmentos:**
        - **3A. Canal Digital**: Sitio web, formularios, entradas en l√≠nea ‚Üí secuencias automatizadas
        - **3B. Canal Eventos**: Open Day, Fogatada, eventos en vivo ‚Üí seguimiento 48h
        - **3C. Canal Mensajer√≠a**: WhatsApp, contacto directo ‚Üí respuesta personalizada y r√°pida
        - **3D. Canal Nicho**: Programas especializados, campa√±as peque√±as ‚Üí evaluaci√≥n de ROI
        
        **Pesta√±as Disponibles:** Resumen, An√°lisis de Segmento, An√°lisis de Actividad, An√°lisis de Preparatoria, Email y Conversi√≥n, Cerradores R√°pidos/Lentos, Per√≠odo Acad√©mico, B√∫squeda de Contactos
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            st.info("**Caso de Uso Principal:** An√°lisis de ROI de eventos, optimizaci√≥n de campa√±as APREU, asociaciones con preparatorias")
        with col2:
            st.success("**Segmentos Esperados:** 4 canales de entrada (3A-3D) con insights de actividad y preparatoria")
    
    st.markdown("---")
    
    # Quick Start Guide
    st.markdown("### üöÄ Gu√≠a de Inicio R√°pido")
    
    st.markdown("""
    **C√≥mo usar esta aplicaci√≥n:**
    
    1. **Selecciona un cluster** desde la navegaci√≥n de la barra lateral
    2. **Explora distribuciones de segmentos** y m√©tricas de rendimiento
    3. **Analiza desgloses detallados** usando filtros interactivos
    4. **Busca contactos individuales** usando la herramienta de b√∫squeda de contactos
    5. **Exporta datos** para an√°lisis adicional o activaci√≥n de campa√±as
    
    **Consejos de Navegaci√≥n:**
    - Usa la **barra lateral** para cambiar entre clusters
    - Cada cluster tiene **m√∫ltiples pesta√±as** para diferentes an√°lisis
    - **Pasa el cursor sobre los gr√°ficos** para informaci√≥n detallada
    - Usa **filtros** para profundizar en segmentos espec√≠ficos
    - La funci√≥n de **b√∫squeda de contactos** est√° disponible en cada cluster
    """)
    
    st.markdown("---")
    
    # Data Quality Summary
    with st.expander("üìã Resumen de Calidad de Datos", expanded=False):
        st.markdown("#### Cobertura de Datos por Cluster")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**Cluster 1: Compromiso Social**")
            social_fields = ['Original Source', 'Latest Traffic Source', 'Broadcast Clicks', 
                           'LinkedIn Clicks', 'Twitter Clicks', 'Facebook Clicks']
            # Handle both original and lowercase column names
            coverage = 0
            for field in social_fields:
                if field in data.columns:
                    coverage += data[field].notna().sum()
                elif field.lower().replace(' ', '_') in data.columns:
                    coverage += data[field.lower().replace(' ', '_')].notna().sum()
            st.metric("Puntos de Datos Disponibles", f"{coverage:,}")
        
        with col2:
            st.markdown("**Cluster 2: Geograf√≠a**")
            geo_fields = ['IP Country', 'IP State/Region', 'Pa√≠s preparatoria BPM', 'Estado de preparatoria BPM']
            coverage = 0
            for field in geo_fields:
                if field in data.columns:
                    coverage += data[field].notna().sum()
                elif field.lower().replace(' ', '_').replace('/', '_') in data.columns:
                    coverage += data[field.lower().replace(' ', '_').replace('/', '_')].notna().sum()
            st.metric("Puntos de Datos Disponibles", f"{coverage:,}")
        
        with col3:
            st.markdown("**Cluster 3: Actividades APREU**")
            apreu_fields = ['Actividades de promoci√≥n APREU', 'First Conversion', 'Recent Conversion']
            coverage = 0
            for field in apreu_fields:
                if field in data.columns:
                    coverage += data[field].notna().sum()
                elif field.lower().replace(' ', '_') in data.columns:
                    coverage += data[field.lower().replace(' ', '_')].notna().sum()
            st.metric("Puntos de Datos Disponibles", f"{coverage:,}")

if __name__ == "__main__":
    main()

